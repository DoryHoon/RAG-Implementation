# π“ μ‚Όμ„±μ „μ 2025 Q4 μ‹¤μ λ°ν‘ RAG μ±—λ΄‡

μ‚Όμ„±μ „μ 2025λ…„ 4λ¶„κΈ° μ‹¤μ λ°ν‘ PDF λ¬Έμ„λ¥Ό κΈ°λ°μΌλ΅, **μ™„μ „ λ¬΄λ£ μ¤ν”μ†μ¤ λ¨λΈλ§** μ‚¬μ©ν•΄ κµ¬μ¶•ν• RAG(Retrieval-Augmented Generation) μ±—λ΄‡μ…λ‹λ‹¤.

---

## π—οΈ μ „μ²΄ μ•„ν‚¤ν…μ²

```
PDF λ¬Έμ„ (2κ°)
    β†“ PyPDFLoader
λ¬Έμ„ λ΅λ“ (49 pages)
    β†“ RecursiveCharacterTextSplitter
ν…μ¤νΈ μ²­ν¬ λ¶„ν•  (92 chunks)
    β†“ HuggingFaceEmbeddings (BAAI/bge-m3)
λ²΅ν„° μ„λ² λ”© μƒμ„± (CUDA GPU ν™μ©)
    β†“ FAISS VectorStore
λ²΅ν„° μ €μ¥ λ° μΈλ±μ‹±
    β†“ Retriever
μ§λ¬Έκ³Ό μ μ‚¬ν• μ²­ν¬ κ²€μƒ‰
    β†“ ChatPromptTemplate
ν”„λ΅¬ν”„νΈ μ΅°ν•© (context + question)
    β†“ HuggingFaceEndpoint (gemma-2-9b-it)
LLM μ¶”λ΅ 
    β†“ StrOutputParser
μµμΆ… λ‹µλ³€ μ¶λ ¥
```

---

## π› οΈ κΈ°μ  μ¤νƒ

| κµ¬μ„± μ”μ† | μ‚¬μ© κΈ°μ  | λΉ„μ© |
|-----------|-----------|------|
| **λ¬Έμ„ λ΅λ”** | `PyPDFLoader` (langchain-community) | λ¬΄λ£ |
| **ν…μ¤νΈ λ¶„ν• ** | `RecursiveCharacterTextSplitter` | λ¬΄λ£ |
| **μ„λ² λ”© λ¨λΈ** | `BAAI/bge-m3` (HuggingFace) | λ¬΄λ£ |
| **λ²΅ν„° DB** | `FAISS` (Facebook AI) | λ¬΄λ£ |
| **LLM** | `google/gemma-2-9b-it` (HuggingFace Inference API) | λ¬΄λ£ |
| **ν”„λ μ„μ›ν¬** | `LangChain` | λ¬΄λ£ |
| **GPU κ°€μ†** | NVIDIA CUDA (RTX 5060 Ti) | - |

---

## π“‚ μ…λ ¥ λ¬Έμ„

- `μ‚Όμ„±_2025Q4_conference_eng_presentation.pdf` (15 pages)
- `μ‚Όμ„±_2025Q4_script_eng_AudioScript.pdf` (34 pages)
- **μ΄ λ΅λ“ νμ΄μ§€ μ: 49 pages**

---

## β™οΈ μ½”λ“ Flow (λ‹¨κ³„λ³„ μ„¤λ…)

### Step 1 β€” ν™κ²½ μ„¤μ • λ° λΌμ΄λΈλ¬λ¦¬ import

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
```

`.env` νμΌμ— HuggingFace API ν† ν°μ„ μ €μ¥ν•κ³  `load_dotenv()`λ΅ λ΅λ“ν•©λ‹λ‹¤.

---

### Step 2 β€” PDF λ¬Έμ„ λ΅λ“

```python
loader = PyPDFLoader(path)
docs.extend(loader.load())
# μ΄ 49νμ΄μ§€ λ΅λ“
```

ν”„λ μ  ν…μ΄μ… μλ£μ™€ μ–΄λ‹μ¤μ½ μ¤λ””μ¤ μ¤ν¬λ¦½νΈ, λ‘ κ°μ PDFλ¥Ό ν•¨κ» λ΅λ“ν•΄ λ” ν’λ¶€ν• μ»¨ν…μ¤νΈλ¥Ό ν™•λ³΄ν•©λ‹λ‹¤.

---

### Step 3 β€” ν…μ¤νΈ λ¶„ν•  (Chunking)

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,   # μ²­ν¬ λ‹Ή μµλ€ 1000μ
    chunk_overlap=50   # λ¬Έλ§¥ μ μ§€λ¥Ό μ„ν•΄ 50μ μ¤λ²„λ©
)
splits = text_splitter.split_documents(docs)
# κ²°κ³Ό: 92κ° μ²­ν¬
```

`chunk_overlap=50`μΌλ΅ μ²­ν¬ κ²½κ³„μ—μ„ λ¬Έλ§¥μ΄ μλ¦¬λ” κ²ƒμ„ λ°©μ§€ν•©λ‹λ‹¤.

---

### Step 4 β€” λ²΅ν„° μ„λ² λ”© λ° FAISS μΈλ±μ‹±

```python
embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={'device': 'cuda'}  # GPU κ°€μ†
)

vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
retriever = vectorstore.as_retriever()
```

- **μ„λ² λ”© λ¨λΈ**: `BAAI/bge-m3` β€” λ΅μ»¬ λ‹¤μ΄λ΅λ“ ν›„ GPUμ—μ„ μ‹¤ν–‰, API λΉ„μ© μ—†μ
- **λ²΅ν„° DB**: FAISS β€” μΈλ©”λ¨λ¦¬ μ €μ¥, λΉ λ¥Έ μ μ‚¬λ„ κ²€μƒ‰

---

### Step 5 β€” LLM μ—°κ²°

```python
llm_endpoint = HuggingFaceEndpoint(
    repo_id="google/gemma-2-9b-it",
    max_new_tokens=1024,
    temperature=0.1,
    huggingfacehub_api_token=hf_token,
)
chat_llm = ChatHuggingFace(llm=llm_endpoint)
```

HuggingFace Inference APIμ **λ¬΄λ£ ν‹°μ–΄**λ¥Ό ν™μ©ν•©λ‹λ‹¤. `gemma-2-9b-it`μ€ μ‚¬μ „μ— [HuggingFace λ¨λΈ νμ΄μ§€](https://huggingface.co/google/gemma-2-9b-it)μ—μ„ λΌμ΄μ„ μ¤ λ™μκ°€ ν•„μ”ν•©λ‹λ‹¤.

ν”„λ΅¬ν”„νΈλ” μ‚Όμ„±μ „μ μ‹¤μ λ°ν‘ μ „λ¬Έκ°€ νλ¥΄μ†λ‚λ΅ μ„¤μ •ν•΄ μμΉ κΈ°λ°μ μ •ν™•ν• λ‹µλ³€μ„ μ λ„ν•©λ‹λ‹¤:

```
λ‹Ήμ‹ μ€ μ‚Όμ„±μ „μ μ‹¤μ λ°ν‘ μ „λ¬Έ AI μ–΄μ‹μ¤ν„΄νΈμ…λ‹λ‹¤.
μ κ³µλ μλ£λ¥Ό λ°”νƒ•μΌλ΅ μμΉλ¥Ό μ •ν™•ν ν¬ν•¨ν•μ—¬ μƒμ„Έν λ‹µλ³€ν•μ„Έμ”.
```

---

### Step 6 β€” RAG μ²΄μΈ κµ¬μ„±

```python
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | chat_llm
    | StrOutputParser()
)
```

LangChainμ LCEL(LangChain Expression Language) νμ΄ν”„λΌμΈμΌλ΅ Retriever β†’ Prompt β†’ LLM β†’ Parserλ¥Ό ν• μ¤„λ΅ μ—°κ²°ν•©λ‹λ‹¤.

---

### Step 7 β€” μ§μμ‘λ‹µ μ‹¤ν–‰

```python
response = rag_chain.invoke("2025 4Q highlightsμ— λ€ν•΄ μµλ€ν• μƒμ„Έν•κ² μ•λ ¤μ¤")
```

---

## π’¬ ν…μ¤νΈ μ§λ¬Έ λ° λ‹µλ³€ μμ‹

**Q: 2025 4Q highlightsμ— λ€ν•΄ μµλ€ν• μƒμ„Έν•κ² μ•λ ¤μ¤**
> λ§¤μ¶ 93.8μ΅° KRW, μμ—…μ΄μµ 20.1μ΅° KRW, μ—°κ°„ λ§¤μ¶ 333.6μ΅° KRW, μμ—…μ΄μµ 43.6μ΅° KRW λ“± μ£Όμ” μ¬λ¬΄ μ§€ν‘λ¥Ό μƒμ„Έν λ‹µλ³€

**Q: HBM4 κ°λ° ν„ν™©μ΄λ‘ 2026λ…„ HBM λ§¤μ¶ μ „λ§ μ•λ ¤μ¤**
> HBM4 μµμΆ… μκ²© κ²€μ¦ λ‹¨κ³„ μ§„μ…, 11.7 Gbps μµκ³  μ„±λ¥ Bin λ€λ‰ μƒμ‚° μ¤‘, 2026λ…„ HBM λ§¤μ¶ μ „λ…„ λ€λΉ„ 3λ°° μ΄μƒ μ¦κ°€ μ „λ§

**Q: 2025λ…„ 4λ¶„κΈ°μ— DSμ‚¬μ—…λ¶€λ” μΆ‹μ•„μ΅λ”λ° DXμ‚¬μ—…λ¶€λ” μ™ λ‚λΉ μ΅μ–΄?**
> μ‹ κ· μ¤λ§νΈν° μ¶μ‹ ν¨κ³Ό μ†λ©Έ λ° λ―Έκµ­ κ΄€μ„Έλ΅ μΈν• κ°€μ „μ ν’ λ¶€μ§„μΌλ΅ DX λ§¤μ¶ 8% QoQ κ°μ† μ„¤λ…

---

## π“¦ μ„¤μΉ λ°©λ²•

```bash
pip install langchain langchain-community langchain-huggingface
pip install faiss-gpu  # GPU λ²„μ „ (CPU: faiss-cpu)
pip install pypdf python-dotenv
```

`.env` νμΌ μƒμ„±:
```
HUGGINGFACEHUB_API_TOKEN=your_token_here
```

> β οΈ HuggingFace ν† ν° λ°κΈ‰ κ³„μ •κ³Ό λ¨λΈ λΌμ΄μ„ μ¤ λ™μ κ³„μ •μ΄ **λ°λ“μ‹ λ™μΌ**ν•΄μ•Ό ν•©λ‹λ‹¤.

---

## π’΅ λ¬΄λ£λ΅ λ§λ“  ν•µμ‹¬ ν¬μΈνΈ

1. **μ„λ² λ”©**: `BAAI/bge-m3`λ¥Ό λ΅μ»¬ GPUμ—μ„ μ‹¤ν–‰ β†’ OpenAI Embedding API λΉ„μ© 0μ›
2. **LLM**: HuggingFace Inference API λ¬΄λ£ ν‹°μ–΄ ν™μ© β†’ OpenAI GPT API λΉ„μ© 0μ›
3. **λ²΅ν„° DB**: FAISS μΈλ©”λ¨λ¦¬ β†’ Pinecone/Weaviate κ°™μ€ μ λ£ λ²΅ν„° DB λΉ„μ© 0μ›
